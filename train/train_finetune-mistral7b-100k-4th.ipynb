{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## Trainning Mistral 7B v·ªõi MetaMathQA_395k (300k - 400k)"],"metadata":{"id":"IIttXMcHwhNO"}},{"cell_type":"code","source":["%%capture\n","!pip install pip3-autoremove\n","!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu124\n","!pip install unsloth vllm\n","# !pip install --upgrade transformers==4.52.3"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:19:36.512932Z","iopub.execute_input":"2025-07-08T06:19:36.513124Z","iopub.status.idle":"2025-07-08T06:24:44.452200Z","shell.execute_reply.started":"2025-07-08T06:19:36.513107Z","shell.execute_reply":"2025-07-08T06:24:44.451268Z"},"id":"EIZjBAe7whNP"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### ƒêƒÉng nh·∫≠p HuggingFace"],"metadata":{"id":"VwmEQfH-whNP"}},{"cell_type":"code","source":["!huggingface-cli login --token $secret_hf"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:24:44.456388Z","iopub.execute_input":"2025-07-08T06:24:44.457065Z","iopub.status.idle":"2025-07-08T06:24:45.043623Z","shell.execute_reply.started":"2025-07-08T06:24:44.457035Z","shell.execute_reply":"2025-07-08T06:24:45.042878Z"},"id":"09ejip38whNQ","outputId":"91820547-a0dc-45a4-ad60-a44041d47754"},"outputs":[{"name":"stdout","text":"usage: huggingface-cli <command> [<args>] login [-h] [--token TOKEN] [--add-to-git-credential]\nhuggingface-cli <command> [<args>] login: error: argument --token: expected one argument\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN_DK\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:51:28.502336Z","iopub.execute_input":"2025-07-08T14:51:28.503120Z","iopub.status.idle":"2025-07-08T14:51:28.566340Z","shell.execute_reply.started":"2025-07-08T14:51:28.503097Z","shell.execute_reply":"2025-07-08T14:51:28.565556Z"},"id":"v4F_qyLrwhNQ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from huggingface_hub import login\n","login(token=hf_token, new_session=False)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:51:30.898886Z","iopub.execute_input":"2025-07-08T14:51:30.899577Z","iopub.status.idle":"2025-07-08T14:51:30.980194Z","shell.execute_reply.started":"2025-07-08T14:51:30.899557Z","shell.execute_reply":"2025-07-08T14:51:30.979595Z"},"id":"Ourc-YHewhNQ"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Load m√¥ h√¨nh Mistral 4bit t·ª´ Unsloth"],"metadata":{"id":"9ybsRGo4whNR"}},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch\n","\n","max_seq_length = 2048  # Chi·ªÅu d√†i t·ªëi ƒëa 1 ƒëo·∫°n vƒÉn b·∫£n\n","dtype = None           # T·ª± ƒë·ªông ch·ªçn (float16, bfloat16) theo GPU\n","load_in_4bit = True    # D√πng m√¥ h√¨nh l∆∞·ª£ng t·ª≠ h√≥a 4-bit\n","lora_rank = 32\n","\n","# Load model ƒë√£ quant h√≥a 4bit + t·ª± ƒë·ªông chia l√™n GPU ph√π h·ª£p\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    fast_inference = True, # Enable vLLM fast inference\n","    max_lora_rank = lora_rank,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:24:50.622374Z","iopub.execute_input":"2025-07-08T06:24:50.622592Z","iopub.status.idle":"2025-07-08T06:25:56.575920Z","shell.execute_reply.started":"2025-07-08T06:24:50.622575Z","shell.execute_reply":"2025-07-08T06:25:56.575194Z"},"colab":{"referenced_widgets":["039443d1527d47f1a635ddef913625f0","a84811a952bb44219f2cf1df59ca3c5b","9f85d09e10364e23a9223e7cdcf96c19","36b89a5de2cc401d9cd621edcd0f52a0","3d6efdd4e2e948d08483d0408c3d4af2","97d1b363cd4840fe95a18514ec45beaf"]},"id":"3R0HuftlwhNR","outputId":"da8db378-2017-4a23-f3f7-f09d0c327b13"},"outputs":[{"name":"stdout","text":"ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-08 06:25:02.491241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751955902.698606      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751955902.763218      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ü¶• Unsloth Zoo will now patch everything to make training faster!\nINFO 07-08 06:25:21 [__init__.py:244] Automatically detected platform cuda.\nUnsloth: vLLM does not work on older GPUs - will switch to Unsloth inference!\n==((====))==  Unsloth 2025.6.12: Fast Mistral patching. Transformers: 4.51.3. vLLM: 0.9.2.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 6.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"039443d1527d47f1a635ddef913625f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a84811a952bb44219f2cf1df59ca3c5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f85d09e10364e23a9223e7cdcf96c19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b89a5de2cc401d9cd621edcd0f52a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d6efdd4e2e948d08483d0408c3d4af2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97d1b363cd4840fe95a18514ec45beaf"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":["### LoRA"],"metadata":{"id":"JXyul76QwhNR"}},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = lora_rank,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:25:56.576878Z","iopub.execute_input":"2025-07-08T06:25:56.577169Z","iopub.status.idle":"2025-07-08T06:26:04.838708Z","shell.execute_reply.started":"2025-07-08T06:25:56.577145Z","shell.execute_reply":"2025-07-08T06:26:04.837802Z"},"id":"f-kn0btlwhNR","outputId":"633468b3-9c20-4bab-f34e-899a6c96a3f7"},"outputs":[{"name":"stderr","text":"Unsloth 2025.6.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["### G√°n Chat Template ki·ªÉu ChatML. Load v√† x·ª≠ l√Ω d·ªØ li·ªáu MetaMathQA"],"metadata":{"id":"GhsvgrK1whNR"}},{"cell_type":"markdown","source":["### Train/test split"],"metadata":{"id":"i9yG4-RcwhNR"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"meta-math/MetaMathQA\", split=\"train\")\n","dataset = dataset.select(range(300000, 395000))  # Ch·ªâ l·∫•y 100k m·∫´u t·ª´ 300000 - 395000\n","print(len(dataset))"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:26:04.840182Z","iopub.execute_input":"2025-07-08T06:26:04.840478Z","iopub.status.idle":"2025-07-08T06:26:18.222593Z","shell.execute_reply.started":"2025-07-08T06:26:04.840451Z","shell.execute_reply":"2025-07-08T06:26:18.221676Z"},"colab":{"referenced_widgets":["ee51682bdfa245e48e912c4f321001b4","f01f6606f5434216b984d135eca449e0","5e42255ae1ae41c18a992011d6d90988"]},"id":"Di0UVUq1whNR","outputId":"3b0ef9f9-d9e4-4dfc-9c2e-9b6eef94d0d9"},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee51682bdfa245e48e912c4f321001b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"MetaMathQA-395K.json:   0%|          | 0.00/396M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f01f6606f5434216b984d135eca449e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/395000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e42255ae1ae41c18a992011d6d90988"}},"metadata":{}},{"name":"stdout","text":"95000\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["split_dataset = dataset.train_test_split(test_size=0.3, seed=42)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:26:18.223780Z","iopub.execute_input":"2025-07-08T06:26:18.224057Z","iopub.status.idle":"2025-07-08T06:26:18.256267Z","shell.execute_reply.started":"2025-07-08T06:26:18.224038Z","shell.execute_reply":"2025-07-08T06:26:18.255674Z"},"id":"eEhyZn8dwhNS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["train_dataset = split_dataset[\"train\"]\n","eval_dataset = split_dataset[\"test\"]"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:26:23.599987Z","iopub.execute_input":"2025-07-08T06:26:23.600308Z","iopub.status.idle":"2025-07-08T06:26:23.604395Z","shell.execute_reply.started":"2025-07-08T06:26:23.600286Z","shell.execute_reply":"2025-07-08T06:26:23.603639Z"},"id":"a6N-tjy_whNS"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Format d·∫°ng h·ªôi tho·∫°i"],"metadata":{"id":"CS3dGpIgwhNS"}},{"cell_type":"code","source":["from unsloth.chat_templates import get_chat_template\n","\n","# G√°n template\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template=\"chatml\",  # ho·∫∑c \"mistral\", \"unsloth\"\n","    map_eos_token=True,\n",")\n","\n","# System Instruction\n","system_instruction_fixed = \"\"\"Below is an instruction that describes a mathematical task.\n","Write a response that thoroughly solves the given problem.\n","Before solving, develop a clear step-by-step chain of reasoning to ensure accuracy and logical coherence.\n","\n","### Instruction:\n","You are a mathematics expert with advanced knowledge in mathematical reasoning, problem-solving, and proof techniques. You think outloud and consider various aspects before giving any concrete answers.\"\"\"\n","\n","def formatting_prompts_func_conversational_structured(examples):\n","    queries = examples[\"query\"]\n","    responses = examples[\"response\"]\n","    texts = []\n","\n","    for q, r in zip(queries, responses):\n","        messages = [\n","            {\"role\": \"system\", \"content\": system_instruction_fixed},\n","            {\"role\": \"user\", \"content\": q},\n","            {\"role\": \"assistant\", \"content\": r},\n","        ]\n","        formatted = tokenizer.apply_chat_template(\n","            messages,\n","            tokenize=False,\n","            add_generation_prompt=False\n","        )\n","        texts.append(formatted)\n","\n","    return {\"text\": texts}\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:26:27.199875Z","iopub.execute_input":"2025-07-08T06:26:27.200194Z","iopub.status.idle":"2025-07-08T06:26:27.543435Z","shell.execute_reply.started":"2025-07-08T06:26:27.200171Z","shell.execute_reply":"2025-07-08T06:26:27.542754Z"},"id":"oYaoOYb6whNS","outputId":"5a14d02e-ff20-4ccb-e6db-e789e4ec826d"},"outputs":[{"name":"stderr","text":"Unsloth: Will map <|im_end|> to EOS = </s>.\nYou are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["train_dataset = train_dataset.map(formatting_prompts_func_conversational_structured, batched=True)\n","eval_dataset = eval_dataset.map(formatting_prompts_func_conversational_structured, batched=True)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:26:32.295804Z","iopub.execute_input":"2025-07-08T06:26:32.296432Z","iopub.status.idle":"2025-07-08T06:26:38.512316Z","shell.execute_reply.started":"2025-07-08T06:26:32.296407Z","shell.execute_reply":"2025-07-08T06:26:38.511375Z"},"colab":{"referenced_widgets":["ae2fae22b4fb427eb1a6512cc241cfab","db4efff008364a2b96b9024f25f37a3b"]},"id":"-pfsN0ScwhNS","outputId":"8a4ba3fe-59e1-4856-bfa4-a792180e40fd"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/66500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae2fae22b4fb427eb1a6512cc241cfab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db4efff008364a2b96b9024f25f37a3b"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":["### Hu·∫•n luy·ªán b·∫±ng `SFTTrainer`"],"metadata":{"id":"12xAs1EZwhNS"}},{"cell_type":"code","source":["from trl import SFTConfig, SFTTrainer\n","\n","# Kh·ªüi t·∫°o Trainer ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi c√°c thi·∫øt l·∫≠p ƒë√£ t·ªëi ∆∞u cho to√°n h·ªçc\n","trainer = SFTTrainer(\n","    model = model,                          # M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã (c√≥ th·ªÉ LoRA ho·∫∑c fine-tuned)\n","    tokenizer = tokenizer,                  # Tokenizer ph√π h·ª£p v·ªõi m√¥ h√¨nh\n","    train_dataset = train_dataset,          # D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c token h√≥a cho hu·∫•n luy·ªán\n","    eval_dataset = eval_dataset,            # D·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° trong qu√° tr√¨nh train\n","    dataset_text_field = \"text\",            # Tr∆∞·ªùng ch·ª©a chu·ªói ƒë·∫ßu v√†o\n","    max_seq_length = 2048,                  # ƒê·ªô d√†i t·ªëi ƒëa m·ªói chu·ªói, ph√π h·ª£p v·ªõi Mistral\n","    dataset_num_proc = 2,                   # S·ªë ti·∫øn tr√¨nh song song ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu\n","    packing = False,                        # Kh√¥ng g·ªôp nhi·ªÅu m·∫´u ng·∫Øn l·∫°i ‚Äì t·ªët h∆°n cho to√°n h·ªçc v√¨ m·∫´u th∆∞·ªùng d√†i\n","    args = SFTConfig(\n","        output_dir = \"outputs\",             # Th∆∞ m·ª•c ƒë·ªÉ l∆∞u checkpoint v√† log\n","        per_device_train_batch_size = 2,    # Batch size m·ªói GPU ‚Äì tƒÉng n·∫øu ƒë·ªß VRAM\n","        per_device_eval_batch_size = 2,     # Batch size khi ƒë√°nh gi√° ‚Äì kh√¥ng ·∫£nh h∆∞·ªüng t·ªëc ƒë·ªô train\n","        gradient_accumulation_steps = 4,    # S·ªë b∆∞·ªõc t√≠ch l≈©y gradient ‚Äì tƒÉng n·∫øu VRAM h·∫°n ch·∫ø\n","        warmup_steps = 60,                  # S·ªë b∆∞·ªõc ƒë·∫ßu warmup learning rate (5% ~ 1000 steps)\n","        max_steps = 1200,                   # T·ªïng s·ªë b∆∞·ªõc hu·∫•n luy·ªán (b·∫°n c√≥ th·ªÉ gi·∫£m n·∫øu c·∫ßn)\n","        learning_rate = 2e-4,               # Learning rate ‚Äì th∆∞·ªùng d√πng 1e-4 cho LoRA\n","        optim = \"adamw_8bit\",               # Optimizer nh·∫π, ph√π h·ª£p v·ªõi m√¥ h√¨nh 4-bit\n","        weight_decay = 0.01,                # Tr√°nh overfitting nh·∫π\n","        lr_scheduler_type = \"cosine\",       # TƒÉng gi·∫£m learning rate m∆∞·ª£t m√† h∆°n ‚Äúlinear‚Äù\n","        logging_steps = 10,                 # In log sau m·ªói 10 b∆∞·ªõc\n","        logging_strategy = \"steps\",\n","        eval_steps = 10,\n","        report_to = \"none\",                 # N·∫øu mu·ªën theo d√µi b·∫±ng wandb th√¨ ƒë·ªïi th√†nh \"wandb\"\n","        seed = 3407,                        # ƒê·∫£m b·∫£o k·∫øt qu·∫£ reproducible n·∫øu c·∫ßn\n","    ),\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:29:06.050532Z","iopub.execute_input":"2025-07-08T06:29:06.051190Z","iopub.status.idle":"2025-07-08T06:29:40.649434Z","shell.execute_reply.started":"2025-07-08T06:29:06.051165Z","shell.execute_reply":"2025-07-08T06:29:40.648198Z"},"colab":{"referenced_widgets":["bf6609722c5c4aa9bb5a724b3f42ae09","dcf2cdc1d9a74f44868d8bc2ef764187"]},"id":"JI8tsGhBwhNS","outputId":"b17de9e2-264d-4d4b-a6f1-49e3e8b503f1"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/66500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf6609722c5c4aa9bb5a724b3f42ae09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/28500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcf2cdc1d9a74f44868d8bc2ef764187"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["# B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán\n","trainer_stats = trainer.train()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T06:29:41.985033Z","iopub.execute_input":"2025-07-08T06:29:41.985999Z","iopub.status.idle":"2025-07-08T14:46:09.137025Z","shell.execute_reply.started":"2025-07-08T06:29:41.985966Z","shell.execute_reply":"2025-07-08T14:46:09.136303Z"},"id":"atlSaMw_whNS","outputId":"a432992f-d2c4-4dad-9cb1-991c1124519f"},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 66,500 | Num Epochs = 1 | Total steps = 1,200\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n \"-____-\"     Trainable parameters = 83,886,080 of 7,000,000,000 (1.20% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1200/1200 8:15:47, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.413000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.687700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.423200</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.414700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.393900</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.377100</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.386000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.369100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.375200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.358800</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.381500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.361000</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.358300</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.360900</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.354700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.335000</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.372300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.354300</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.361600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.371400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.355500</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.350000</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.348400</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.365400</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.337400</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.376100</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.338100</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.326800</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.359400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.352800</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.330400</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.341200</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.341800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.352600</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.333400</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.336800</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.350300</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.349200</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.336800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.322700</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.335600</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.331800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.351400</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.329800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.341300</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.338300</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.330700</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.348900</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.333600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.336800</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.319900</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.356600</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.328900</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.329100</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.327200</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.315700</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.327300</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.339400</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.322100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.344600</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.319400</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.303900</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.329000</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.349300</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.327400</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.306500</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.320700</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.337000</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.323200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.320600</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.305400</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.299400</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.307600</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.360700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.312600</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.321200</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.310100</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.320500</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.316500</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.323700</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.296500</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.312200</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.281000</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.300700</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.297400</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.307600</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.290600</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.302500</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.317800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.297500</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.297700</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.310300</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.302800</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.296400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.320400</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.295100</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.300100</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.288400</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.270900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.285500</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.302400</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.312900</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.299900</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.302100</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.308400</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.290600</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.305400</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.303300</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.291600</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.297500</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.288400</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.298800</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.300100</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.308300</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.307200</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.287200</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.316300</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.279200</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.297500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.302600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["trainer_stats"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:50:02.187691Z","iopub.execute_input":"2025-07-08T14:50:02.188281Z","iopub.status.idle":"2025-07-08T14:50:02.193416Z","shell.execute_reply.started":"2025-07-08T14:50:02.188257Z","shell.execute_reply":"2025-07-08T14:50:02.192644Z"},"id":"KUuV39a8whNT","outputId":"cf606b2a-7dc5-42f3-8abb-2ed9cc4fc05f"},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1200, training_loss=0.33991364121437073, metrics={'train_runtime': 29784.503, 'train_samples_per_second': 0.322, 'train_steps_per_second': 0.04, 'total_flos': 1.8215400436826112e+17, 'train_loss': 0.33991364121437073})"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":["### Inference sau khi hu·∫•n luy·ªán"],"metadata":{"id":"9D9zY7ZxwhNT"}},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","from unsloth.chat_templates import get_chat_template\n","from transformers import TextStreamer\n","import torch\n","\n","# K√≠ch ho·∫°t ch·∫ø ƒë·ªô inference nhanh\n","FastLanguageModel.for_inference(model)\n","\n","# G·∫Øn l·∫°i chat template chu·∫©n chatml (ho·∫∑c mistral n·∫øu fine-tune theo ki·ªÉu ƒë√≥)\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template=\"chatml\",\n","    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\"},\n","    map_eos_token=True,\n",")\n","\n","# H√†m h·ªèi ƒë√°p inference\n","def chat(question, max_new_tokens=512, stream=False):\n","    messages = [{\"from\": \"human\", \"value\": question}]\n","\n","    # T·∫°o prompt theo chu·∫©n chat\n","    inputs = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=True,\n","        add_generation_prompt=True,\n","        return_tensors=\"pt\",\n","    ).to(\"cuda\")\n","\n","    # T√πy ch·ªçn stream ra m√†n h√¨nh tr·ª±c ti·∫øp\n","    if stream:\n","        streamer = TextStreamer(tokenizer)\n","        _ = model.generate(\n","            input_ids=inputs,\n","            streamer=streamer,\n","            max_new_tokens=max_new_tokens,\n","            do_sample=False,\n","            temperature=0.0,\n","            top_p=1.0,\n","            top_k=1,\n","            repetition_penalty=1.1,\n","            use_cache=True,\n","            pad_token_id=tokenizer.eos_token_id,\n","        )\n","    else:\n","        # Sinh ra k·∫øt qu·∫£ ho√†n ch·ªânh\n","        outputs = model.generate(\n","            input_ids=inputs,\n","            max_new_tokens=max_new_tokens,\n","            do_sample=False,\n","            temperature=0.0,\n","            top_p=1.0,\n","            top_k=1,\n","            repetition_penalty=1.1,\n","            use_cache=True,\n","            pad_token_id=tokenizer.eos_token_id,\n","        )\n","\n","        # Gi·∫£i m√£ k·∫øt qu·∫£\n","        result = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","\n","        # C·∫Øt ph·∫ßn prompt n·∫øu c·∫ßn\n","        response = result.split(question.strip())[-1].strip()\n","        return response\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:52:59.040205Z","iopub.execute_input":"2025-07-08T14:52:59.040505Z","iopub.status.idle":"2025-07-08T14:52:59.355499Z","shell.execute_reply.started":"2025-07-08T14:52:59.040485Z","shell.execute_reply":"2025-07-08T14:52:59.354959Z"},"id":"iiL1NHEgwhNT","outputId":"608853c3-e3ec-44f7-c23e-3d80beac76a8"},"outputs":[{"name":"stderr","text":"Unsloth: Will map <|im_end|> to EOS = <|im_end|>.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["response = chat(\"If $x - y = X and $x + y = 12$, what is the value of $x$? If we know the answer to the above question is 9, what is the value of unknown variable X?\")\n","print(response) # ƒê√∫ng"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:53:01.960576Z","iopub.execute_input":"2025-07-08T14:53:01.961139Z","iopub.status.idle":"2025-07-08T14:53:13.235008Z","shell.execute_reply.started":"2025-07-08T14:53:01.961117Z","shell.execute_reply":"2025-07-08T14:53:13.234382Z"},"id":"x-VXEA9ZwhNT","outputId":"6c01792f-dfc3-451c-d545-1380419046d8"},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>assistant\nWe are given two equations:\n$x - y = X$ (Equation 1)\n$x + y = 12$ (Equation 2)\nTo find the value of $x$, we can solve these equations simultaneously.\nWe can start by adding Equation 1 and Equation 2 together:\n$(x - y) + (x + y) = X + 12$\nSimplifying this equation gives us:\n$2x = X + 12$\nNow, we can substitute the value of $X$ into this equation:\n$2x = 9 + 12$\n$2x = 21$\nDividing both sides of the equation by 2, we get:\n$x = \\frac{21}{2}$\nThe value of $x$ is $\\frac{21}{2}$.\nThe answer is: 21\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["chat(\"A radio show plays for 3 hours a day. They split their show into talking segments, ad breaks and songs. Talking segments last 10 minutes each, ad breaks last 5 minutes each and songs are played throughout the rest of the show. If the radio show includes 3 talking segments and x ad breaks in today‚Äôs show, how long, in minutes, does the show play songs? If we know the answer to the above question is 125, what is the value of unknown variable x?\", stream=True)\n","# ƒê√∫ng"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:55:37.057419Z","iopub.execute_input":"2025-07-08T14:55:37.057727Z","iopub.status.idle":"2025-07-08T14:55:50.505448Z","shell.execute_reply.started":"2025-07-08T14:55:37.057690Z","shell.execute_reply":"2025-07-08T14:55:50.504792Z"},"id":"VJkc2hIzwhNT","outputId":"47edc6d0-e603-409d-81c7-2dd63755bf89"},"outputs":[{"name":"stdout","text":"<|im_start|>user\nA radio show plays for 3 hours a day. They split their show into talking segments, ad breaks and songs. Talking segments last 10 minutes each, ad breaks last 5 minutes each and songs are played throughout the rest of the show. If the radio show includes 3 talking segments and x ad breaks in today‚Äôs show, how long, in minutes, does the show play songs? If we know the answer to the above question is 125, what is the value of unknown variable x?<|im_end|>\n<|im_start|>assistant\nThe total duration of the show is 3 hours * 60 minutes/hour = 180 minutes.\nTalking segments last 10 minutes each, so 3 talking segments will take up 10 * 3 = 30 minutes.\nAd breaks last 5 minutes each, so x ad breaks will take up 5x minutes.\nSongs are played throughout the rest of the show, which means they take up 180 - 30 - 5x minutes.\nWe are given that the show plays songs for 125 minutes, so we can write: 180 - 30 - 5x = 125.\nSimplifying the left side, we get: 150 - 5x = 125.\nSubtracting 150 from both sides, we get: -5x = -25.\nDividing both sides by -5, we get: x = 5.\nThe value of x is 5.\n#### 5\nThe answer is: 5<|im_end|>\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["response = chat(\"In a charity race to raise money for hurricane victims, thirty students participated. Ten of them raised $20 each, while the remaining students raised $30 each. What is the total amount of money raised by the students in the race?\")\n","print(response)\n","# ƒê√∫ng"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:55:57.928292Z","iopub.execute_input":"2025-07-08T14:55:57.928565Z","iopub.status.idle":"2025-07-08T14:56:03.530738Z","shell.execute_reply.started":"2025-07-08T14:55:57.928545Z","shell.execute_reply":"2025-07-08T14:56:03.530022Z"},"id":"ZsEWlOIswhNT","outputId":"1f8ccb53-9ec6-4a54-dec2-7f4a4e948ac0"},"outputs":[{"name":"stdout","text":"<|im_start|>assistant\nThe ten students who raised $20 each contributed 10 * $20 = $200.\nThe remaining twenty students who raised $30 each contributed 20 * $30 = $600.\nTherefore, the total amount of money raised by the students in the race is $200 + $600 = $800.\n#### 800\nThe answer is: 800\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["chat(\"Which two-digit positive integer is one more than a multiple of 2, 3, 4, 5, and 6?\", stream=True)\n","# Sai, ƒë√°p l√†: 61"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:56:06.224423Z","iopub.execute_input":"2025-07-08T14:56:06.224672Z","iopub.status.idle":"2025-07-08T14:56:07.911621Z","shell.execute_reply.started":"2025-07-08T14:56:06.224655Z","shell.execute_reply":"2025-07-08T14:56:07.911091Z"},"id":"0_0l_gxtwhNT","outputId":"271e7a09-959b-41e2-a2cb-7483e598c6d8"},"outputs":[{"name":"stdout","text":"<|im_start|>user\nWhich two-digit positive integer is one more than a multiple of 2, 3, 4, 5, and 6?<|im_end|>\n<|im_start|>assistant\nThe only number that satisfies all five conditions is $\\boxed{10}$.\nThe answer is: 10<|im_end|>\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["chat(\"Simplify: $|{-3^2+4}|$\", stream=True)\n","# ƒê√∫ng :5"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:56:16.927516Z","iopub.execute_input":"2025-07-08T14:56:16.927995Z","iopub.status.idle":"2025-07-08T14:56:20.090562Z","shell.execute_reply.started":"2025-07-08T14:56:16.927974Z","shell.execute_reply":"2025-07-08T14:56:20.089724Z"},"id":"v_54dlBMwhNT","outputId":"f27a2167-4f59-4134-96e6-96c127889598"},"outputs":[{"name":"stdout","text":"<|im_start|>user\nSimplify: $|{-3^2+4}|$<|im_end|>\n<|im_start|>assistant\nFirst, we simplify the expression inside the absolute value: $3^2-4=9-4=5$.\nThen, we take the absolute value of 5: $|5|=\\boxed{5}$.The answer is: 5<|im_end|>\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["chat(\"Steven's teacher sends the class an assignment to collect x different fruit seeds. Apples average 6 seeds, pears average 2 seeds, and grapes average 3 seeds. Steven has set aside 4 apples, 3 pears, and 9 grapes to extract their seeds. How many more seeds does he need to fulfill his assignment? If we know the answer to the above question is 3, what is the value of unknown variable x?\")\n","# ƒê√°p √°n 60 => ƒê√∫ng"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:56:29.663353Z","iopub.execute_input":"2025-07-08T14:56:29.663632Z","iopub.status.idle":"2025-07-08T14:56:40.976803Z","shell.execute_reply.started":"2025-07-08T14:56:29.663609Z","shell.execute_reply":"2025-07-08T14:56:40.976226Z"},"id":"5Cfm1fcowhNT","outputId":"2c67b37b-0a9b-4bfa-8026-d560111ec8e7"},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>assistant\\nSteven has set aside 4 apples, which means he has 4 * 6 = 24 apple seeds.\\nHe also has 3 pears, which means he has 3 * 2 = 6 pear seeds.\\nAnd he has 9 grapes, which means he has 9 * 3 = 27 grape seeds.\\nThe total number of seeds he already has is 24 + 6 + 27 = 57 seeds.\\nTo fulfill his assignment, he needs to collect x different fruit seeds.\\nSo the number of additional seeds he needs is x - 57.\\nWe are given that the number of additional seeds needed is 3, so we can write: x - 57 = 3.\\nSolving for x, we get: x = 60.\\nThe value of x is 60.\\n#### 60\\nThe answer is: 60'"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["chat(\n","\"\"\"I am a two-digit number.\n","The sum of my digits is 11.\n","If you reverse my digits, the new number = the original number + 27.\n","What number am I?\n","\"\"\",\n","    stream=True\n",")\n","# ƒê√°p √°n: 47 => Sai"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:56:47.768417Z","iopub.execute_input":"2025-07-08T14:56:47.768691Z","iopub.status.idle":"2025-07-08T14:56:54.231606Z","shell.execute_reply.started":"2025-07-08T14:56:47.768671Z","shell.execute_reply":"2025-07-08T14:56:54.230857Z"},"id":"h-aXsZTzwhNT","outputId":"8033f3c1-cc88-486c-cba8-f5d7075d0eef"},"outputs":[{"name":"stdout","text":"<|im_start|>user\nI am a two-digit number.\nThe sum of my digits is 11.\nIf you reverse my digits, the new number = the original number + 27.\nWhat number am I?\n<|im_end|>\n<|im_start|>assistant\nLet's call the two-digit number $AB$.\nWe are given that $A+B=11$ and $AB+27=AB+38$.\nSimplifying the second equation gives us $AB=38$.\nSubstituting this into the first equation gives us $A+B=11$, so $A=6$ and $B=5$.\nTherefore, the two-digit number is $\\boxed{65}$.\nThe answer is: 65<|im_end|>\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["chat(\"At Frank's Fruit Market, 3 bananas cost as much as 2 apples, and 6 apples cost as much as 4 oranges. How many oranges cost as much as 18 bananas?\", stream=True)\n","# Sai, ƒë√°p √°n l√† 8"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:56:57.105197Z","iopub.execute_input":"2025-07-08T14:56:57.105549Z","iopub.status.idle":"2025-07-08T14:57:20.824999Z","shell.execute_reply.started":"2025-07-08T14:56:57.105526Z","shell.execute_reply":"2025-07-08T14:57:20.824357Z"},"id":"X2bksJLJwhNU","outputId":"96b571b1-83ef-4046-99ef-f1bd179e16fa"},"outputs":[{"name":"stdout","text":"<|im_start|>user\nAt Frank's Fruit Market, 3 bananas cost as much as 2 apples, and 6 apples cost as much as 4 oranges. How many oranges cost as much as 18 bananas?<|im_end|>\n<|im_start|>assistant\nLet $b$ represent the number of bananas, $a$ represent the number of apples, and $o$ represent the number of oranges. We are given that $3b=2a$, $6a=4o$, and $18b=xo$.\n\nWe can solve these equations to find the values of $b$, $a$, and $o$.\n\nFrom $3b=2a$, we have $b=\\frac{2}{3}a$.\n\nSubstituting this into $6a=4o$, we get $\\frac{2}{3}a=\\frac{4}{6}o$.\n\nSimplifying, we have $a=\\frac{2}{3}o$.\n\nNow, let's substitute these values into $18b=xo$:\n\n$18\\left(\\frac{2}{3}a\\right)=x\\left(\\frac{2}{3}o\\right)$.\n\nMultiplying both sides by 3 to eliminate the fractions, we get $54a=6ox$.\n\nSubstituting $a=\\frac{2}{3}o$, we have $54\\left(\\frac{2}{3}o\\right)=6o\\left(\\frac{2}{3}o\\right)$.\n\nSimplifying, we have $36o=2o^2$.\n\nDividing both sides by $2o$, we get $18o=o^2$.\n\nRearranging, we have $o^2-18o=0$.\n\nFactoring, we have $(o-9)(o+2)=0$.\n\nSo, $o=9$ or $o=-2$. Since we cannot have a negative number of oranges, we have $o=\\boxed{9}$.The answer is: 9<|im_end|>\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["# from transformers import pipeline\n","\n","# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","# questions = [\n","#     \"What is the integral of x^2?\",\n","#     \"Define a group in abstract algebra.\",\n","#     \"Prove that the square root of 2 is irrational.\",\n","# ]\n","\n","# for q in questions:\n","#     prompt = tokenizer.apply_chat_template(\n","#         [{\"role\": \"user\", \"content\": q}],\n","#         tokenize=False,\n","#         add_generation_prompt=True,\n","#     )\n","#     output = pipe(prompt, max_new_tokens=512, do_sample=True, temperature=0.7)\n","#     print(f\"\\n‚ùì {q}\\nüß† {output[0]['generated_text']}\\n\" + \"-\"*60)\n"],"metadata":{"trusted":true,"jupyter":{"source_hidden":true},"id":"73qbY7pewhNU"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### L∆∞u m√¥ h√¨nh"],"metadata":{"id":"e0tVIP5AwhNX"}},{"cell_type":"markdown","source":["#### T·∫£i m√¥ h√¨nh"],"metadata":{"id":"qHJaX8P9whNY"}},{"cell_type":"code","source":["model.save_pretrained(\"mistral-metamathqa-lora-100k-p4\")\n","tokenizer.save_pretrained(\"mistral-metamathqa-lora-100k-p4\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:00:36.595178Z","iopub.execute_input":"2025-07-08T15:00:36.595551Z","iopub.status.idle":"2025-07-08T15:00:37.447729Z","shell.execute_reply.started":"2025-07-08T15:00:36.595528Z","shell.execute_reply":"2025-07-08T15:00:37.447136Z"},"id":"b4QCi4rCwhNY","outputId":"e776e4a8-5a9d-41c3-c8c3-93fdefea09ca"},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"('mistral-metamathqa-lora-100k-p4/tokenizer_config.json',\n 'mistral-metamathqa-lora-100k-p4/special_tokens_map.json',\n 'mistral-metamathqa-lora-100k-p4/tokenizer.json')"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["import shutil\n","\n","shutil.make_archive(\n","    base_name=\"/kaggle/working/mistral-metamathqa-lora-100k-p4\",  # T√™n file zip (kh√¥ng c·∫ßn .zip ·ªü ƒë√¢y)\n","    format=\"zip\",  # C√≥ th·ªÉ l√†: 'zip', 'tar', 'gztar', 'bztar', 'xztar'\n","    root_dir=\"/kaggle/working/mistral-metamathqa-lora-100k-p4\"\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:00:40.386923Z","iopub.execute_input":"2025-07-08T15:00:40.387364Z","iopub.status.idle":"2025-07-08T15:00:58.022907Z","shell.execute_reply.started":"2025-07-08T15:00:40.387333Z","shell.execute_reply":"2025-07-08T15:00:58.022244Z"},"id":"8kGzk2t-whNY","outputId":"62110e6f-f129-49c8-820e-c78c0dca39c5"},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/mistral-metamathqa-lora-100k-p4.zip'"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":["### Load m√¥ h√¨nh l√™n HuggingFace"],"metadata":{"id":"-O3UnLWswhNY"}},{"cell_type":"code","source":["from huggingface_hub import create_repo\n","\n","create_repo(\"mistral-metamathqa-lora-100k-p4\", private=False)  # ho·∫∑c private=False n·∫øu mu·ªën c√¥ng khai"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:02:29.521754Z","iopub.execute_input":"2025-07-08T15:02:29.522088Z","iopub.status.idle":"2025-07-08T15:02:30.180691Z","shell.execute_reply.started":"2025-07-08T15:02:29.522065Z","shell.execute_reply":"2025-07-08T15:02:30.180133Z"},"id":"S60P-ORMwhNY","outputId":"28cf28cf-5a5d-42cb-e2d4-14875687fecf"},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/KenyaWashed/mistral-metamathqa-lora-100k-p4', endpoint='https://huggingface.co', repo_type='model', repo_id='KenyaWashed/mistral-metamathqa-lora-100k-p4')"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["from huggingface_hub import HfApi\n","\n","api = HfApi()\n","api.upload_folder(\n","    folder_path=\"/kaggle/working/mistral-metamathqa-lora-100k-p4\",\n","    repo_id=\"KenyaWashed/mistral-metamathqa-lora-100k-p4\",  # s·ª≠a l·∫°i ƒë√∫ng username Hugging Face c·ªßa b·∫°n\n","    repo_type=\"model\"\n",")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T15:02:33.554020Z","iopub.execute_input":"2025-07-08T15:02:33.554598Z","iopub.status.idle":"2025-07-08T15:02:42.337028Z","shell.execute_reply.started":"2025-07-08T15:02:33.554576Z","shell.execute_reply":"2025-07-08T15:02:42.336382Z"},"colab":{"referenced_widgets":["5c905a574c5f444b8edf9baefdfb18b6"]},"id":"G9Z0VXvDwhNY","outputId":"f974e838-4c18-49dc-d2fc-5cb02b8bb54c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c905a574c5f444b8edf9baefdfb18b6"}},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/KenyaWashed/mistral-metamathqa-lora-100k-p4/commit/ae6e7ea2efd7d02f5c1764d65f4b427db892d911', commit_message='Upload folder using huggingface_hub', commit_description='', oid='ae6e7ea2efd7d02f5c1764d65f4b427db892d911', pr_url=None, repo_url=RepoUrl('https://huggingface.co/KenyaWashed/mistral-metamathqa-lora-100k-p4', endpoint='https://huggingface.co', repo_type='model', repo_id='KenyaWashed/mistral-metamathqa-lora-100k-p4'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":null}]}